{
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ATP ranking stats"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " Importing the required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "We're going to download our data from [ATP World Tour tennis data](https://datahub.io/sports-data/atp-world-tour-tennis-data/r/rankings_1973-2017.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p data/\n",
    "if not os.path.exists('data/rankings_1973-2017.csv'):\n",
    "    !curl -sSL -o data/rankings_1973-2017.csv https://datahub.io/sports-data/atp-world-tour-tennis-data/r/rankings_1973-2017.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "atp_rankings = pd.read_csv('data/rankings_1973-2017.csv', dtype={'week_title': object, 'week_year': int, 'week_month': int, 'week_day': int, 'rank_text': object, 'rank_number': int, 'move_position': float, 'move_direction': object, 'player_age': float, 'ranking_points': int, 'tourneys_played': int, 'player_url': object, 'player_slug': object, 'player_id': object})"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lets take a look at the size of our data set. The shape attribute gives us (as a tuple) the number of rows and the number of columns in the data that we loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "(2694539, 14)\n"
    }
   ],
   "source": [
    "print(atp_rankings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "We can also look at what type of data each column contains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "week_title          object\nweek_year            int64\nweek_month           int64\nweek_day             int64\nrank_text           object\nrank_number          int64\nmove_positions     float64\nmove_direction      object\nplayer_age         float64\nranking_points       int64\ntourneys_played      int64\nplayer_url          object\nplayer_slug         object\nplayer_id           object\ndtype: object\n"
    }
   ],
   "source": [
    "print(atp_rankings.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Since we will not use the whole data set lets subset our data by the columns we will need. We want to get out the week_year, week_month, week_day, rank_number and player_age, and save this into a new variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "rankings_subset = atp_rankings[['week_year', 'week_month', 'week_day', 'rank_number', 'player_age']]"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lets take a look at how much missing data is in our data set. We can use the isnull method from numpy to count how many values in our dataset are missing. We can also look at specific columns of our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "214559\n0\n0\n214559\n"
    }
   ],
   "source": [
    "print(np.count_nonzero(rankings_subset.isnull()))\n",
    "print(np.count_nonzero(rankings_subset['week_year'].isnull()))\n",
    "print(np.count_nonzero(rankings_subset['rank_number'].isnull()))\n",
    "print(np.count_nonzero(rankings_subset['player_age'].isnull()))"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Since all of the missing data is in the player_age column we will need to keep that in mind when we analyse the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_all_years(df):\n",
    "    all_years = df['week_year'].unique()\n",
    "    all_years.sort()\n",
    "    all_years_list = all_years.tolist()\n",
    "    return all_years_list\n",
    "\n",
    "def find_last_date(df, year):\n",
    "    search_year = df[df['week_year'] == year]\n",
    "    search_month = sorted(search_year['week_month'].unique())[-1]\n",
    "    search_year_search_month = search_year[search_year['week_month'] == search_month]\n",
    "    search_day = sorted(search_year_search_month['week_day'].unique())[-1]\n",
    "    return search_month, search_day\n",
    "\n",
    "def year_end_top_100(df, year):\n",
    "    last_month, last_day = find_last_date(df, year)\n",
    "    search_year = df[df['week_year'] == year]\n",
    "    year_end_month = search_year[search_year['week_month'] == last_month]\n",
    "    year_end_day = year_end_month[year_end_month['week_day'] == last_day]\n",
    "    sorted_top = year_end_day.sort_values(by=['rank_number'])\n",
    "    top_100 = sorted_top[:100]\n",
    "    age_top_100 = top_100['player_age'].values\n",
    "    age_top_100_list = age_top_100.tolist()\n",
    "    return age_top_100_list\n",
    "\n",
    "def year_end_rank(df, year):\n",
    "    last_month, last_day = find_last_date(df, year)\n",
    "    search_year = df[df['week_year'] == year]\n",
    "    year_end_month = search_year[search_year['week_month'] == last_month]\n",
    "    year_end_day = year_end_month[year_end_month['week_day'] == last_day]\n",
    "    sorted_top = year_end_day.sort_values(by=['rank_number'])\n",
    "    return sorted_top\n",
    "\n",
    "def find_youngest_in_top_100(df, year):\n",
    "    last_month, last_day = find_last_date(df, year)\n",
    "    search_year = df[df['week_year'] == year]\n",
    "    year_end_month = search_year[search_year['week_month'] == last_month]\n",
    "    year_end_day = year_end_month[year_end_month['week_day'] == last_day]\n",
    "    sorted_top = year_end_day.sort_values(by=['rank_number'])\n",
    "    top_100 = sorted_top[:100]\n",
    "    find_youngest = sorted(top_100['player_age'].unique())[0]\n",
    "    return find_youngest\n",
    "\n",
    "def find_oldest_in_top_100(df, year):\n",
    "    last_month, last_day = find_last_date(df, year)\n",
    "    search_year = df[df['week_year'] == year]\n",
    "    year_end_month = search_year[search_year['week_month'] == last_month]\n",
    "    year_end_day = year_end_month[year_end_month['week_day'] == last_day]\n",
    "    sorted_top = year_end_day.sort_values(by=['rank_number'])\n",
    "    top_100 = sorted_top[:100]\n",
    "    top_100_clean = top_100.dropna()\n",
    "    find_oldest = sorted(top_100_clean['player_age'].unique())[-1]\n",
    "    return find_oldest"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "When analysing the average age of players in the top 100 we have to ignore the missing values. For that we use the nanmean function from numpy to compute the arithmetic mean ignoring the NaNs. When finding the youngest and oldest player, we used the dropna function from pandas to remove any missing values so that we do not get the wrong result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "averages_for_every_year = []\n",
    "for year in find_all_years(rankings_subset):\n",
    "   average_100 = np.nanmean(year_end_top_100(rankings_subset, year))\n",
    "   averages_for_every_year.append(average_100)\n",
    "\n",
    "youngest_for_every_year = []\n",
    "for year in find_all_years(rankings_subset):\n",
    "   youngest = find_youngest_in_top_100(rankings_subset, year)\n",
    "   youngest_for_every_year.append(youngest)\n",
    "\n",
    "oldest_for_every_year = []\n",
    "for year in find_all_years(rankings_subset):\n",
    "   oldest = find_oldest_in_top_100(rankings_subset, year)\n",
    "   oldest_for_every_year.append(oldest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[1973, 1974, 1975, 1976, 1977, 1978, 1979, 1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017]\n"
    }
   ],
   "source": [
    "print(find_all_years(rankings_subset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[26.45, 26.76, 26.62, 26.949494949494948, 27.01, 26.19, 26.08, 28.0, 21.0, 20.0, 25.12, 24.61, 23.92, 23.57, 23.74, 23.71, 24.18, 24.08, 24.25, 24.21, 24.56, 25.1, 24.6, 24.89, 24.94, 25.0, 24.93, 25.12, 24.89, 24.98, 25.1, 25.33, 25.23, 25.52, 25.59, 25.89, 26.31, 26.29, 26.67, 27.22, 27.64, 27.76, 27.62, 28.06, 28.13]\n"
    }
   ],
   "source": [
    "print(averages_for_every_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[17.0, 17.0, 18.0, 19.0, 12.0, 18.0, 19.0, 28.0, 21.0, 20.0, 18.0, 17.0, 17.0, 16.0, 17.0, 16.0, 17.0, 18.0, 19.0, 18.0, 19.0, 19.0, 19.0, 18.0, 19.0, 17.0, 18.0, 18.0, 19.0, 18.0, 17.0, 18.0, 18.0, 18.0, 18.0, 19.0, 21.0, 20.0, 19.0, 20.0, 20.0, 19.0, 18.0, 19.0, 18.0]\n"
    }
   ],
   "source": [
    "print(youngest_for_every_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 38.0, 28.0, 21.0, 20.0, 32.0, 33.0, 34.0, 34.0, 35.0, 36.0, 37.0, 32.0, 39.0, 40.0, 33.0, 34.0, 31.0, 32.0, 32.0, 33.0, 35.0, 35.0, 34.0, 32.0, 33.0, 34.0, 35.0, 34.0, 35.0, 36.0, 37.0, 34.0, 33.0, 34.0, 35.0, 36.0, 36.0, 37.0, 38.0]\n"
    }
   ],
   "source": [
    "print(oldest_for_every_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}